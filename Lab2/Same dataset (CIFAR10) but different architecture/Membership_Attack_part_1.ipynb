{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack - part-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veereshthotigar/CSEE5590-490-AI-CyberSecurity-/blob/master/Lab2/Same%20dataset%20(CIFAR10)%20but%20different%20architecture/Membership_Attack_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "3b71efc6-b68d-483e-8bad-919c88f28970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/cybersecurity/Lab-Assignment-2/Part-2'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "24140f3c-d321-4ca8-f3ec-19a7c141dbb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "1111d3ed-40b8-49c7-d9e3-e96e6b4eef8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  dog  ship  deer  ship\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "bb6a81a9-5da4-4aa5-f8e1-9551ecd74c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2m0DwoK5Xt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YejeqA68933D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yAlGMwn5f78",
        "colab_type": "text"
      },
      "source": [
        "Below is the preTrained Target Model loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbLKKajm5eUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/../../target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Target model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD6Yc_R44QCX",
        "colab_type": "text"
      },
      "source": [
        "Below is Shadow Model Architecture different from target model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygSJAmC94UjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# Shadow Model Architecture\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class shadow(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(shadow, self).__init__()\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(3*32*32, 2304),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(2304, 1536),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1536, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 768),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlOhiXBHLV0H",
        "colab_type": "code",
        "outputId": "dd9b2c94-0e7b-44c9-ffc1-8e1f6db40ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "af770329-8fdd-4fef-902d-9ac0f1a77275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "shadow_model = shadow()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.SGD(shadow_model.parameters(), lr=0.001) # SGD \n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 2.3021997776031493\n",
            "\n",
            "Epoch : 2/20.. Training loss: 2.2993014295578003\n",
            "\n",
            "Epoch : 3/20.. Training loss: 2.295217490005493\n",
            "\n",
            "Epoch : 4/20.. Training loss: 2.2881613527297975\n",
            "\n",
            "Epoch : 5/20.. Training loss: 2.271895202255249\n",
            "\n",
            "Epoch : 6/20.. Training loss: 2.2317551002502443\n",
            "\n",
            "Epoch : 7/20.. Training loss: 2.1594572323799133\n",
            "\n",
            "Epoch : 8/20.. Training loss: 2.0930086928367615\n",
            "\n",
            "Epoch : 9/20.. Training loss: 2.0530957913398744\n",
            "\n",
            "Epoch : 10/20.. Training loss: 2.0281572698593138\n",
            "\n",
            "Epoch : 11/20.. Training loss: 2.0064695532798766\n",
            "\n",
            "Epoch : 12/20.. Training loss: 1.9861209619522096\n",
            "\n",
            "Epoch : 13/20.. Training loss: 1.9675459579467773\n",
            "\n",
            "Epoch : 14/20.. Training loss: 1.9463089265823363\n",
            "\n",
            "Epoch : 15/20.. Training loss: 1.9284512697219849\n",
            "\n",
            "Epoch : 16/20.. Training loss: 1.9057356109619141\n",
            "\n",
            "Epoch : 17/20.. Training loss: 1.8796040097236633\n",
            "\n",
            "Epoch : 18/20.. Training loss: 1.8651349051475525\n",
            "\n",
            "Epoch : 19/20.. Training loss: 1.8411611392974854\n",
            "\n",
            "Epoch : 20/20.. Training loss: 1.8203672404289246\n",
            "Our model: \n",
            "\n",
            " shadow(\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=2304, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Linear(in_features=2304, out_features=1536, bias=True)\n",
            "    (3): ReLU(inplace)\n",
            "    (4): Linear(in_features=1536, out_features=1024, bias=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): Dropout(p=0.1)\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Linear(in_features=1024, out_features=768, bias=True)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Dropout(p=0.1)\n",
            "    (13): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (14): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHZNbnkgRCZ0",
        "colab_type": "code",
        "outputId": "8be6c4b1-aa3f-4ec5-a518-a0d09cb28e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the {len(shadow_out_loader)*batch_size} test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 32 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAIYt1goU0VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating dataset for attack model\n",
        "batch_size = 1\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "cd676e6f-c564-4a69-99fe-d4c01c144db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# freeze the Shadow model \n",
        "for param in shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[13000]) \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.00609359, 0.00206916, 0.29256177, 0.06364521, 0.27405864,\n",
            "       0.06943358, 0.20059602, 0.08902471, 0.00084006, 0.00167723],\n",
            "      dtype=float32), 1]\n",
            "[array([0.02691486, 0.2077902 , 0.01213186, 0.1813663 , 0.02052958,\n",
            "       0.19525434, 0.04078931, 0.10007112, 0.05975549, 0.15539697],\n",
            "      dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFRCL63ZqkRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "    \n",
        "# make predictions on both datasets (target_in and target_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Continued in part - 2"
      ]
    }
  ]
}