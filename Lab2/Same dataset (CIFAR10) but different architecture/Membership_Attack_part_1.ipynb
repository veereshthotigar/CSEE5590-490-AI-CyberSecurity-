{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack - part-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veereshthotigar/CSEE5590-490-AI-CyberSecurity-/blob/master/Lab2/Same%20dataset%20(CIFAR10)%20but%20different%20architecture/Membership_Attack_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "f05ddada-a716-49f8-e88c-36d74fca3912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/cybersecurity/Lab-Assignment-2/Part-2'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "21ab8f8e-595e-474a-ca7b-f917a80a70e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/My Drive/cybersecurity/Lab-Assignment-2/Part-2/data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 27458524.47it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "608dc11e-af6a-41f9-d34c-621ba2bc551c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "plane plane  deer truck\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "ea9c53be-6bbb-41f4-c08c-1d0393fc1280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2m0DwoK5Xt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yAlGMwn5f78",
        "colab_type": "text"
      },
      "source": [
        "Below is the preTrained Target Model loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbLKKajm5eUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/../../target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Target model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD6Yc_R44QCX",
        "colab_type": "text"
      },
      "source": [
        "Below is Shadow Model Architecture different from target model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygSJAmC94UjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# Shadow Model Architecture\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class shadow(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(shadow, self).__init__()\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(3*32*32, 2304),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(2304, 1536),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1536, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 768),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlOhiXBHLV0H",
        "colab_type": "code",
        "outputId": "7dc54f5f-269c-41f0-cdbf-2894b64af8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "9160aa1e-579e-4c9c-9855-c1af35c8fa7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "shadow_model = shadow()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.003) # ADAM \n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/40.. Training loss: 2.35042440612793\n",
            "\n",
            "Epoch : 2/40.. Training loss: 2.303900334625244\n",
            "\n",
            "Epoch : 3/40.. Training loss: 2.303753274002075\n",
            "\n",
            "Epoch : 4/40.. Training loss: 2.3037507942962647\n",
            "\n",
            "Epoch : 5/40.. Training loss: 2.3040810263824465\n",
            "\n",
            "Epoch : 6/40.. Training loss: 2.3039118954467774\n",
            "\n",
            "Epoch : 7/40.. Training loss: 2.3037847388458252\n",
            "\n",
            "Epoch : 8/40.. Training loss: 2.3325814567184446\n",
            "\n",
            "Epoch : 9/40.. Training loss: 2.3035141457366946\n",
            "\n",
            "Epoch : 10/40.. Training loss: 2.303568374710083\n",
            "\n",
            "Epoch : 11/40.. Training loss: 2.3034756452941894\n",
            "\n",
            "Epoch : 12/40.. Training loss: 2.3038089839935303\n",
            "\n",
            "Epoch : 13/40.. Training loss: 2.3037385453033448\n",
            "\n",
            "Epoch : 14/40.. Training loss: 2.303823454208374\n",
            "\n",
            "Epoch : 15/40.. Training loss: 2.303901102523804\n",
            "\n",
            "Epoch : 16/40.. Training loss: 2.303787969894409\n",
            "\n",
            "Epoch : 17/40.. Training loss: 2.303529346008301\n",
            "\n",
            "Epoch : 18/40.. Training loss: 2.303608746414185\n",
            "\n",
            "Epoch : 19/40.. Training loss: 2.3037585190582277\n",
            "\n",
            "Epoch : 20/40.. Training loss: 2.303129225616455\n",
            "\n",
            "Epoch : 21/40.. Training loss: 2.3038726251220703\n",
            "\n",
            "Epoch : 22/40.. Training loss: 2.3092548387527465\n",
            "\n",
            "Epoch : 23/40.. Training loss: 2.3037632893371582\n",
            "\n",
            "Epoch : 24/40.. Training loss: 2.303802936706543\n",
            "\n",
            "Epoch : 25/40.. Training loss: 2.303485824356079\n",
            "\n",
            "Epoch : 26/40.. Training loss: 2.30360020690918\n",
            "\n",
            "Epoch : 27/40.. Training loss: 2.3035532011413573\n",
            "\n",
            "Epoch : 28/40.. Training loss: 2.3036099647521975\n",
            "\n",
            "Epoch : 29/40.. Training loss: 2.3037258396148683\n",
            "\n",
            "Epoch : 30/40.. Training loss: 2.3037755250549314\n",
            "\n",
            "Epoch : 31/40.. Training loss: 2.303861268234253\n",
            "\n",
            "Epoch : 32/40.. Training loss: 2.3036396572875977\n",
            "\n",
            "Epoch : 33/40.. Training loss: 2.303692929611206\n",
            "\n",
            "Epoch : 34/40.. Training loss: 2.303600178604126\n",
            "\n",
            "Epoch : 35/40.. Training loss: 2.3036339865875246\n",
            "\n",
            "Epoch : 36/40.. Training loss: 2.30377776763916\n",
            "\n",
            "Epoch : 37/40.. Training loss: 2.3037899789428713\n",
            "\n",
            "Epoch : 38/40.. Training loss: 2.3036200509643554\n",
            "\n",
            "Epoch : 39/40.. Training loss: 2.303717514266968\n",
            "\n",
            "Epoch : 40/40.. Training loss: 2.3035376100158693\n",
            "Our model: \n",
            "\n",
            " shadow(\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=2304, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Linear(in_features=2304, out_features=1536, bias=True)\n",
            "    (3): ReLU(inplace)\n",
            "    (4): Linear(in_features=1536, out_features=1024, bias=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): Dropout(p=0.1)\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Linear(in_features=1024, out_features=768, bias=True)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Dropout(p=0.1)\n",
            "    (13): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (14): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHZNbnkgRCZ0",
        "colab_type": "code",
        "outputId": "3103fc50-8a9e-4faf-d9fa-d14efc6d46f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the {len(shadow_out_loader)*batch_size} test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 9 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAIYt1goU0VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating dataset for attack model\n",
        "batch_size = 1\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "2488b65c-4acf-4dce-f90a-290eb73b851d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[13000]) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.69812787, 0.0056684 , 0.04928311, 0.06875259, 0.00446699,\n",
            "       0.08649439, 0.00238252, 0.03545161, 0.01053014, 0.03884223],\n",
            "      dtype=float32), 1]\n",
            "[array([2.3185348e-06, 1.8340063e-05, 1.9232699e-03, 2.8209519e-03,\n",
            "       1.4139616e-02, 3.7749086e-02, 9.4329131e-01, 4.7475736e-05,\n",
            "       7.2393818e-06, 7.3020817e-07], dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFRCL63ZqkRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "    \n",
        "# make predictions on both datasets (target_in and target_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffqsLQIn5ru_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Continued in part - 2"
      ]
    }
  ]
}