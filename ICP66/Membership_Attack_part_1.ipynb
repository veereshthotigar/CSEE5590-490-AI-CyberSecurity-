{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack - part-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veereshthotigar/CSEE5590-490-AI-CyberSecurity-/blob/master/ICP66/Membership_Attack_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "5ce0d5c9-e822-43ba-d58c-034027deb51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/cybersecurity'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "64cbcb39-40c7-44f9-e86c-190900cd6878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "830ac4f0-c1ed-492c-ab7d-88883a1c69c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " ship   cat  deer   car\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "83f84c31-375a-4c93-cd51-613be7f52dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlOhiXBHLV0H",
        "colab_type": "code",
        "outputId": "5f985e75-7961-49c6-944d-563814c4f1a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "9a0e89d3-156a-42d6-a37d-6cd28f213d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.8244312032104453\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.485248245165476\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3047055429052514\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.172107183834171\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.071331743046146\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9883724807016075\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9165249565411406\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8456001576712674\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.8111682481244397\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7544909132182446\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7064726629754161\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6724331111878233\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6397756493228781\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.612105106418033\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5876148832042504\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5533996513827949\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5276659991773193\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.49949834106104146\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.4795182778754884\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.46036122160751725\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "02aa3ea8-f64f-4026-bf86-66f98f261249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "6f642682-61b0-4eab-dff8-559524123915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.7799088058569241\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4394232090324393\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.2692151035341765\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1432739201256685\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0590352466725328\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.988750673316019\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9179964718001578\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8627103782828202\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.8085271851981387\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7663954184831255\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7213324548681374\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6922098126005182\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6498805219331361\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.620220743205465\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5923808011252557\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5743136791240834\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5409594801161677\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.5107546067508437\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.48497929268747647\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.47178841437525154\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHZNbnkgRCZ0",
        "colab_type": "code",
        "outputId": "fbaf049b-46fa-4c8f-b4cd-cfc984cf1fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 74 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmnk_ZVJWPF0",
        "colab_type": "text"
      },
      "source": [
        "Got the same accuracy as target model since I have used same architecture and hyperparameters !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocvC5oilXnXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAIYt1goU0VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "2488b65c-4acf-4dce-f90a-290eb73b851d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[13000]) \n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.69812787, 0.0056684 , 0.04928311, 0.06875259, 0.00446699,\n",
            "       0.08649439, 0.00238252, 0.03545161, 0.01053014, 0.03884223],\n",
            "      dtype=float32), 1]\n",
            "[array([2.3185348e-06, 1.8340063e-05, 1.9232699e-03, 2.8209519e-03,\n",
            "       1.4139616e-02, 3.7749086e-02, 9.4329131e-01, 4.7475736e-05,\n",
            "       7.2393818e-06, 7.3020817e-07], dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFRCL63ZqkRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffqsLQIn5ru_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Continued in part - 2"
      ]
    }
  ]
}